# NoSQL
1.	Key-Value存储，如Amaze Dynamo等，可根据CAP三原则灵活选择不同倾向的数据库产品。
2.	领域模型 + 分布式缓存 + 存储 （Qi4j和NoSql运动），可根据CAP三原则结合自己项目定制灵活的分布式方案，难度高。

## 1. 分类
* KV键值 key-value memcahed, redis
* 面向文档 document mongoDB, couchDB
* 面向列 column hbase, cassandra 开源分布式NoSQL数据库系统

## 2. 一致性哈希
consistent hashing
1. 先构造一个长度为2^32的整数环（这个环被称为一致性Hash环）
2. 根据节点名称的Hash值（其分布为[0, 2^32-1]）将服务器节点放置在这个Hash环上
3. 根据数据的Key值计算得到其Hash值（其分布也为[0, 2^32-1]）
4. 接着在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。

引入“虚拟节点”。其工作原理是：将一个物理节点拆分为多个虚拟节点，并且同一个物理节点的虚拟节点尽量均匀分布在Hash环上。采取这样的方式，就可以有效地解决增加或减少节点时候的负载不均衡的问题。

算法原理
1.	环形空间  0 ~ 2^32 -1  
2.	把对象映射到hash空间
3.	把cache映射到hash空间
4.	把对象映射到cache	  顺时针查找关联
5.	考察cache变动  添加、删除cache
6.	虚拟节点

* 单调性 尽可能不影响已分配
* 平衡性 尽可能均匀分布

JedisPool连一台Redis，
ShardedJedisPool连Redis集群，通过一致性哈希算法决定把数据存到哪台上，算是一种客户端负载均衡，所以添加是用这个（Redis 3.0之后支持服务端负载均衡）
删除那个问题的答案就显而易见了，总不可能随机找一个Redis服务端去删吧

## 3. 实现

### 3.1 Redis
Redis是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。

数据库的工作模式按存储方式可分为：硬盘数据库和内存数据库。
Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。

Redis采用的是**基于内存**的采用的是**单进程单线程模型**的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。

#### 3.1.1 特点
1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
3. 采用单线程，避免了不必要的**上下文切换和竞争条件**，也**不存在多进程或者多线程导致的切换**而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4. 使用I/O多路复用模型，非阻塞IO；这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。
5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

#### 3.1.2 网络编程
单线程、NIO、异步

#### 3.1.3 [Redis是单线程](https://blog.csdn.net/chenyao1994/article/details/79491337)
单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。

Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。

redis用**单个CPU绑定**一块内存的数据，然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它是单线程处理这个事。
redis作为单进程模型的程序，为了充分利用多核CPU，常常在一台server上会启动多个实例。而为了减少切换的开销，有必要为每个实例指定其所运行的CPU。

redis的瓶颈在网络上。
多线程缺点：上下文切换、锁、竞争成本

#### 3.1.4 [什么时候用多线程的方案呢](https://blog.csdn.net/world6/article/details/79381682)
下层的存储等慢速的情况。比如磁盘。

对于磁盘来说，它吞吐量这么大，那最好的方案肯定是我将N个请求一起放在一个buff里，然后一起去提交。

方法就是用异步：将请求和处理的线程不绑定，请求的线程将请求放在一个buff里，然后等buff快满了，处理的线程再去处理这个buff。然后由这个buff 统一的去写入磁盘，或者读磁盘，这样效率就是最高。

对于慢速设备，这种处理方式就是最佳的，慢速设备有**磁盘**，**网络**，SSD 等等。多线程 ，异步的方式处理这些问题非常常见，大名鼎鼎的netty 就是这么干的。

#### 3.1.5 过期策略
如果假设你设置一个一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？定期删除+惰性删除

#### 3.1.6 内存淘汰机制
- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适）
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除

#### 3.1.7 [spring-redis](https://www.cnblogs.com/superfj/p/9232482.html) 
* 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 
* 支持丰富数据类型，支持string，list，set，sorted set，hash 
* 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 
* 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

### 3.2 memcached
多线程

redis与memcached

|          | reids | memcached                  |
| :------- | :---- | :------------------------- |
| 数据类型 | 丰富  |                            |
| 集群模式 |       | 原生不支持，需要客户端支持 |


内存分配：
- slab -> page -chunk
- 钙化问题：LRU算法不足之处，内存空间不足以分配新的Slab情况下，这时只会在同一类Slab内部踢出数据。
  如，分配300Byte的slab，mc分配了大量的384大小的slab，只用了一部分384slab，很多空闲的384slab；此时有大点对象来，LRU频繁剔除缓存，回收。
- Slab钙化降低内存使用率
  - 分批重启Memcached实例，启动后重新分配Slab class；注意预热，防止雪崩
  - 开启auto_remove


## 4. 新的问题
* [缓存穿透、缓存击穿、缓存雪崩区别和解决方案](https://blog.csdn.net/kongtiao5/article/details/82771694)
* [缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题](https://blog.csdn.net/xlgen157387/article/details/79530877)

### 4.1 不一致
缓存与数据库双写不一致


| 缓存问题     | 产生原因               | 解决方案                                            |
| :----------- | :--------------------- | :-------------------------------------------------- |
| 缓存更新方式 | 数据变更、缓存时效性   | 同步更新、失效更新，异步更新、定时更新              |
| 缓存不一致   | 同步更新失败，异步更新 | 增加重试、补偿任务，  最终一致                      |
| 缓存穿透     | 恶意攻击               | 空对象缓存、bloomFilter过滤器                       |
| 缓存击穿     | 热点key失效            | 互斥更新、随机退避、差异失效时间                    |
| 缓存雪崩     | 缓存挂掉               | 快速失败熔断，主从模式（主从复制 + 哨兵）、集群模式 |

### 4.2 并发竞争
1. 利用redis自带的incr命令
2. 使用独占锁的方式
3. 使用乐观锁的方式 watch multi exec
4. 客户端针对同一key的资源，进行加锁（synchronized、lock）
5. 利用redis的setnx实现内置的锁

### 4.3 更新
* FIFO算法：First in First out，先进先出。
* LFU算法：Least Frequently Used，最不经常使用算法。
* LRU算法：Least Recently Used，近期最少使用算法。

### 4.5 穿透
缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。

解决方案：
1. 对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。还有最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
2. 采用一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

### 4.6 击穿
缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

解决方案：
1. 设置热点数据永远不过期。
2. 加互斥锁

### 4.7 雪崩
缓存崩溃与快速恢复问题、持久化、容灾

如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。
缓存雪崩是指缓存中数据**大批量**到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指**并发查同一条数据**，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。
这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。

解决方法
1. 在缓存失效后，通过**加锁或者队列**来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
2. 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前**手动触发加载**缓存
3. 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
4. 做二级缓存，或者**双缓存策略**。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。

### 4.8 预热
解决思路：
1. 直接写个缓存刷新页面，上线时手工操作下；
2. 数据量不大，可以在项目启动的时候自动进行加载；
3. 定时刷新缓存；

### 4.9 降级
当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到**核心流程**的性能时，仍然需要保证服务还是可用的，即使是有损服务。
系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。
在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案
